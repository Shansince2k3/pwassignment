{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b61e3012-b161-405f-ad68-54602f707a13",
   "metadata": {},
   "source": [
    "## Question No. 1:\n",
    "\n",
    "## Explain the following with examples:\n",
    "\n",
    "    1. Artificial Intelligence\n",
    "    2. Machine Learning\n",
    "    3. Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf778c34-b5b4-42a8-a064-d624b6c9b550",
   "metadata": {},
   "source": [
    "## Ans\n",
    "---------\n",
    "\n",
    "1. **Artificial Intelligence (AI)**:\n",
    "\n",
    "   **Definition**: Artificial Intelligence (AI) is a broad field of computer science that aims to create machines, software, or systems capable of performing tasks that typically require human intelligence, such as problem-solving, decision-making, understanding natural language, and recognizing patterns.\n",
    "   AI can be divided into two main categories:\n",
    "\n",
    "    > Narrow or Weak AI\n",
    "    \n",
    "    > General or Strong AI\n",
    "\n",
    "\n",
    "   **Example**: Virtual Personal Assistants like Siri or Alexa are good examples of AI. These systems can understand spoken language, answer questions, set reminders, and even control smart devices. They use natural language processing and machine learning techniques to improve their responses based on user interactions.\n",
    "\n",
    "2. **Machine Learning (ML)**:\n",
    "\n",
    "   **Definition**: Machine Learning is a subset of AI that focuses on the development of algorithms and statistical models that enable computers to improve their performance on a specific task through learning from data.\n",
    "   \n",
    "   Machine learning algorithms can be classified into three main categories:\n",
    "\n",
    "    > Supervised Learning\n",
    "    \n",
    "    > Unsupervised Learning\n",
    "    \n",
    "    > Reinforcement Learning\n",
    "\n",
    "\n",
    "   **Example**: One common example is email spam detection. Machine learning algorithms can be trained on a dataset of emails labeled as spam or not spam. The algorithm learns patterns in the data, such as common words or phrases in spam emails, and can then classify new, unseen emails as either spam or not spam based on what it has learned.\n",
    "\n",
    "3. **Deep Learning (DL)**:\n",
    "\n",
    "   **Definition**: Deep Learning is a subfield of machine learning that uses deep neural networks, typically with multiple layers (hence \"deep\"), to automatically learn and represent data. It's particularly suited for tasks involving large amounts of data and complex patterns.\n",
    "\n",
    "   **Example**: Image recognition is a classic use case for deep learning. Convolutional Neural Networks (CNNs), a type of deep learning model, can be trained to recognize objects in images. For example, a deep learning model could learn to identify cats in photographs by analyzing patterns in the pixels, without explicit programming for cat features. Deep learning has also been used in natural language processing for tasks like language translation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3022415a-b655-444e-8ece-4d2a8fde6c21",
   "metadata": {},
   "source": [
    "## Question No. 2:\n",
    "## What is supervised learning? List some examples of supervised learnin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b51555-fe8d-422f-b3bc-42581106e410",
   "metadata": {},
   "source": [
    "## Ans\n",
    "-------\n",
    "**Supervised learning** is a type of machine learning where an algorithm learns from labeled training data to make predictions or decisions without being explicitly programmed. In supervised learning, the algorithm is provided with a dataset consisting of input-output pairs, and it learns to map the inputs to the correct outputs.\n",
    "\n",
    "Here's how supervised learning works:\n",
    "\n",
    "1. **Training Data**: You have a dataset that includes both input data and the corresponding correct output labels.\n",
    "\n",
    "2. **Learning**: The supervised learning algorithm analyzes the training data to learn the underlying patterns and relationships between inputs and outputs.\n",
    "\n",
    "3. **Prediction**: Once the model is trained, it can be used to make predictions or classifications on new, unseen data.\n",
    "\n",
    "Examples of supervised learning tasks include:\n",
    "\n",
    "1. **Image Classification**: Given a dataset of images, each labeled with a specific object or category (e.g., cats and dogs), a supervised learning algorithm can learn to classify new images into these categories. Example algorithms include Convolutional Neural Networks (CNNs).\n",
    "\n",
    "2. **Spam Email Detection**: In email classification, an algorithm can be trained to distinguish between spam and non-spam emails based on features in the email content or metadata.\n",
    "\n",
    "3. **Handwriting Recognition**: Recognizing handwritten digits, as seen in digit recognition tasks like reading zip codes on envelopes or recognizing digits on checks, is a classic supervised learning problem.\n",
    "\n",
    "4. **Language Translation**: Machine translation, like Google Translate, uses supervised learning to translate text from one language to another. Pairs of sentences in both languages serve as the training data.\n",
    "\n",
    "5. **Medical Diagnosis**: In healthcare, supervised learning models can be trained to diagnose diseases based on patient data, such as medical images (e.g., X-rays) or patient records.\n",
    "\n",
    "6. **Stock Price Prediction**: Using historical stock price data as training examples, an algorithm can be trained to predict future stock prices.\n",
    "\n",
    "7. **Autonomous Driving**: In autonomous vehicles, supervised learning is used to recognize objects like pedestrians and other vehicles in the vehicle's surroundings, enabling it to make driving decisions.\n",
    "\n",
    "8. **Recommendation Systems**: Platforms like Netflix and Amazon use supervised learning to recommend movies, products, or content to users based on their previous preferences and behaviors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2afe08-957d-4e7e-a08e-cc5828a7776c",
   "metadata": {},
   "source": [
    "## Question No. 3:\n",
    "## What is unsupervised learning? List some examples of unsupervised learning.?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbc299b-745e-4ea6-9278-7ac56257ba12",
   "metadata": {},
   "source": [
    "## Ans\n",
    "-------\n",
    "**Unsupervised learning** is a type of machine learning where an algorithm learns from unlabeled data, aiming to discover hidden patterns, structures, or relationships within that data. Unlike supervised learning, there are no explicit labels or target outputs provided in unsupervised learning. The algorithm explores the data on its own to find meaningful information.\n",
    "\n",
    "Here's how unsupervised learning works:\n",
    "\n",
    "1. **Unlabeled Data**: You have a dataset that contains only input data, without any associated output labels.\n",
    "\n",
    "2. **Learning**: The unsupervised learning algorithm analyzes the data to identify patterns, group similar data points, or reduce the dimensionality of the data.\n",
    "\n",
    "3. **Exploration**: The primary goal is often to uncover hidden structures or relationships within the data that can be useful for various purposes, such as clustering or dimensionality reduction.\n",
    "\n",
    "Examples of unsupervised learning tasks include:\n",
    "\n",
    "1. **Clustering**: Clustering algorithms group similar data points together based on their similarities or distances in feature space. For instance, K-Means clustering can group customers based on their purchasing behavior, helping in market segmentation.\n",
    "\n",
    "2. **Principal Component Analysis (PCA)**: PCA is a dimensionality reduction technique used to transform high-dimensional data into a lower-dimensional representation while preserving as much variance as possible. It's often used in data preprocessing and visualization.\n",
    "\n",
    "3. **Anomaly Detection**: Unsupervised learning can be used to detect unusual patterns or anomalies in data. This is particularly valuable in fraud detection, where abnormal transactions can be flagged.\n",
    "\n",
    "4. **Topic Modeling**: Algorithms like Latent Dirichlet Allocation (LDA) can identify topics within a collection of documents. This is useful for organizing and summarizing large text datasets.\n",
    "\n",
    "5. **Dimensionality Reduction**: Techniques like t-Distributed Stochastic Neighbor Embedding (t-SNE) can reduce the dimensionality of data for visualization purposes while preserving the relationships between data points.\n",
    "\n",
    "6. **Density Estimation**: Unsupervised learning algorithms can estimate the probability density function of a dataset, which is useful in various statistical analyses.\n",
    "\n",
    "7. **Generative Modeling**: Generative models, such as Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs), can generate new data points that are similar to those in the training data. These models have applications in image generation, text generation, and more.\n",
    "\n",
    "8. **Recommendation Systems**: In some cases, unsupervised learning techniques can be used to group similar users or items without explicit labels, which can be helpful in recommendation systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f27ae31-47d2-4e03-a600-83fdd5e1d513",
   "metadata": {},
   "source": [
    "## Question No. 4:\n",
    "## What is the difference between AI, ML, DL, and DS?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24ec0ac-106f-4706-87f3-4963fa878f76",
   "metadata": {},
   "source": [
    "## Ans\n",
    "-------\n",
    "\n",
    "\n",
    "| Aspect                   | Artificial Intelligence (AI) | Machine Learning (ML)       | Deep Learning (DL)         | Data Science (DS)        |\n",
    "|--------------------------|------------------------------|-----------------------------|-----------------------------|---------------------------|\n",
    "| Definition                | A broad field of computer science aiming to create intelligent machines capable of human-like tasks. | A subset of AI focused on developing algorithms that learn patterns from data to make predictions or decisions. | A specialized subset of ML that uses deep neural networks to learn complex patterns directly from data. | An interdisciplinary field that involves the extraction of insights, knowledge, and value from data using various techniques. |\n",
    "| Scope                    | Encompasses a wide range of technologies and applications, including ML and DL. | Focuses on creating algorithms that can learn and make predictions from data. | Specializes in neural networks with multiple layers for complex pattern recognition. | Encompasses various techniques, including statistics, data analysis, machine learning, and more. |\n",
    "| Data Requirements        | Can work with labeled or unlabeled data. | Requires labeled data for supervised learning; can also work with unlabeled data for unsupervised learning. | Requires labeled data for training deep neural networks. | Utilizes various data types, including structured and unstructured data. |\n",
    "| Example Application     | Virtual Personal Assistants (e.g., Siri, Alexa), Robotics, Natural Language Processing. | Spam Email Detection, Image Classification, Recommender Systems. | Image Recognition, Speech Recognition, Natural Language Processing. | Business Analytics, Predictive Modeling, Data Visualization. |\n",
    "| Complexity               | Covers a wide range of tasks, from simple rule-based systems to complex autonomous decision-making. | Complexity depends on the specific ML algorithm used; can range from simple linear regression to deep neural networks. | Often used for tasks requiring a high degree of complexity and large datasets. | Complexity varies based on the data analysis and modeling tasks involved. |\n",
    "| Key Techniques           | Rule-based systems, expert systems, knowledge representation. | Regression, classification, clustering, dimensionality reduction. | Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), Generative Adversarial Networks (GANs). | Data cleaning, data exploration, statistical analysis, machine learning. |\n",
    "| Hardware Dependencies    | Can be implemented on a wide range of hardware, from traditional CPUs to specialized AI hardware. | Can be implemented on CPUs and GPUs; DL benefits from GPUs and specialized hardware accelerators. | Highly dependent on GPUs and specialized hardware accelerators due to computational demands. | Generally less hardware-intensive compared to DL. |\n",
    "| Goal                     | To create intelligent systems capable of performing tasks that require human-like intelligence. | To develop algorithms that can learn from data and make predictions or decisions. | To enable machines to automatically learn and represent complex patterns from data. | To extract valuable insights and knowledge from data for informed decision-making. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15047507-77a5-4ab7-928b-d119f5492e99",
   "metadata": {},
   "source": [
    "## Question No. 5:\n",
    "## What are the main differences between supervised learning, unsupervised learning, and semi-supervised learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c0d90a-ead5-4902-880d-d9a8ade680c8",
   "metadata": {},
   "source": [
    "## Ans\n",
    "------\n",
    "\n",
    "| Aspect                                 | Supervised Learning | Unsupervised Learning | Semi-Supervised Learning |\n",
    "|----------------------------------------|---------------------|-----------------------|---------------------------|\n",
    "| Type of Data                           | Labeled data        | Unlabeled data        | Combination of labeled and unlabeled data |\n",
    "| Objective                              | Predict or classify based on provided labels | Discover patterns, structures, or relationships within data | Leverage labeled data and unlabeled data to improve performance |\n",
    "| Common Applications                    | Image classification, spam email detection, regression tasks | Clustering, dimensionality reduction, topic modeling | Speech recognition with limited labeled data, image classification with large unlabeled datasets |\n",
    "| Guidance                               | Algorithm is guided by known output labels | Algorithm explores data without predefined labels | Utilizes both labeled data for guidance and unlabeled data for additional information |\n",
    "| Example Algorithms                     | Decision Trees, Random Forest, Support Vector Machines | K-Means Clustering, Principal Component Analysis (PCA), t-SNE | Variational Autoencoders (VAEs), self-training models, co-training models |\n",
    "| Use Cases                              | When labeled data is available and the goal is to make predictions or classifications | To discover hidden structures or group similar data points together when labeled data is scarce or unavailable | When limited labeled data is supplemented with a large amount of unlabeled data to improve model performance |\n",
    "| Data Requirement                       | Requires a dataset with labeled examples | Works with datasets that do not have predefined output labels | Utilizes a combination of labeled and unlabeled data, with a smaller portion being labeled |\n",
    "| Primary Learning Mechanism              | Mapping inputs to outputs based on labeled data | Exploring inherent data patterns without labels | Combining supervised and unsupervised learning principles |\n",
    "| Data Size Impact on Model Performance   | Model performance often improves with more labeled data | Model performance can benefit from larger amounts of unlabeled data | Model performance can improve as more unlabeled data becomes available |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af07b89d-09ca-45e8-b0ce-e134474f9584",
   "metadata": {},
   "source": [
    "## Question No. 6:\n",
    "## What is train, test and validation split? Explain the importance of each term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311f6b13-5b3f-466b-b2f2-46e4f6f3ed6e",
   "metadata": {},
   "source": [
    "## Ans \n",
    "-------\n",
    "1. **Training Data**:\n",
    "\n",
    "   - **Definition**: The training data is a subset of the dataset that is used to train or teach the machine learning model. It consists of input features and their corresponding output labels (in supervised learning) or the data itself (in unsupervised learning).\n",
    "   \n",
    "   - **Importance**: \n",
    "     - **Model Learning**: The primary purpose of the training data is to allow the model to learn the underlying patterns and relationships within the data. The model adjusts its parameters or internal representation during training to minimize errors and make accurate predictions or classifications.\n",
    "     - **Parameter Tuning**: Training data is used to optimize the model's parameters or hyperparameters through techniques like gradient descent. This process helps the model generalize well to unseen data.\n",
    "   \n",
    "2. **Testing Data**:\n",
    "\n",
    "   - **Definition**: The testing data, also called the test set, is another subset of the dataset that is kept separate from the training data. It is used to evaluate the model's performance after training.\n",
    "   \n",
    "   - **Importance**:\n",
    "     - **Performance Evaluation**: The testing data provides an independent dataset that the model has never seen during training. It is used to assess how well the model generalizes to new, unseen data.\n",
    "     - **Overfitting Detection**: Testing data helps detect overfitting, where the model learns the training data too well but fails to generalize. If the model performs well on the training data but poorly on the testing data, it might be overfitting.\n",
    "   \n",
    "3. **Validation Data**:\n",
    "\n",
    "   - **Definition**: The validation data, or validation set, is yet another subset of the dataset that is distinct from both the training and testing data. It is primarily used for model selection and hyperparameter tuning.\n",
    "   \n",
    "   - **Importance**:\n",
    "     - **Hyperparameter Tuning**: Machine learning models often have hyperparameters that are not learned during training. Instead, they are set before training begins. The validation data helps in choosing the best set of hyperparameters by testing various configurations.\n",
    "     - **Preventing Data Leakage**: Using the testing data for hyperparameter tuning can lead to data leakage, where information from the testing set inadvertently influences the model. The validation set prevents this by providing a separate dataset for fine-tuning the model.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355a80ce-d5c2-4523-a66e-71b1d199f237",
   "metadata": {},
   "source": [
    "## Question No. 7:\n",
    "## How can unsupervised learning be used for anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0008ba21-4606-4bb3-8163-db8799e76d39",
   "metadata": {},
   "source": [
    "## Ans\n",
    "-------\n",
    "Unsupervised learning can be a valuable approach for anomaly detection by identifying patterns or structures within data and flagging data points that deviate significantly from these patterns. Here's a general process for using unsupervised learning for anomaly detection:\n",
    "\n",
    "1. **Data Preparation**:\n",
    "   - Collect and preprocess the data: Gather the dataset containing the observations you want to analyze for anomalies. This data should ideally contain normal (non-anomalous) examples.\n",
    "   - Preprocess the data: Standardize, normalize, or transform the data as necessary to make it suitable for unsupervised learning algorithms.\n",
    "\n",
    "2. **Feature Selection/Extraction**:\n",
    "   - Choose relevant features: Identify the features or attributes in your dataset that are most relevant for detecting anomalies. Feature engineering may be necessary to create meaningful features.\n",
    "   \n",
    "3. **Unsupervised Learning Algorithm Selection**:\n",
    "   - Choose an unsupervised learning algorithm: Several algorithms can be used for anomaly detection, including:\n",
    "     - **Clustering Algorithms**: Such as K-Means or DBSCAN, which group similar data points together. Anomalies are often data points that don't belong to any cluster.\n",
    "     - **Dimensionality Reduction**: Techniques like Principal Component Analysis (PCA) or t-Distributed Stochastic Neighbor Embedding (t-SNE) can help reduce the dimensionality of data while highlighting anomalies.\n",
    "     - **Autoencoders**: A type of neural network designed to encode data and then decode it back to its original form. Anomalies can result in higher reconstruction errors.\n",
    "     - **Isolation Forest**: A tree-based algorithm that isolates anomalies by partitioning the data into subsets.\n",
    "     - **One-Class SVM**: A Support Vector Machine (SVM) trained to classify data points as either normal or anomalies, with the majority of points assumed to be normal.\n",
    "  \n",
    "4. **Model Training**:\n",
    "   - Apply the chosen unsupervised learning algorithm to your preprocessed data to create a model that captures the underlying patterns of the normal data.\n",
    "\n",
    "5. **Anomaly Detection**:\n",
    "   - Once the model is trained, apply it to new data points. The model will produce some measure of anomaly score or distance from the learned normal patterns.\n",
    "   - Set a threshold: Define a threshold (e.g., based on statistical methods) that separates normal data from anomalies. Data points with scores exceeding this threshold are flagged as anomalies.\n",
    "\n",
    "6. **Evaluation and Refinement**:\n",
    "   - Evaluate the performance of your anomaly detection system using labeled data if available (where anomalies are known). Metrics like precision, recall, and the F1-score can be used.\n",
    "   - Refine the model and threshold as needed based on the evaluation results.\n",
    "\n",
    "7. **Deployment**:\n",
    "   - Deploy the anomaly detection system to monitor new data in real-time or batch processes. Continuously collect new data and retrain the model periodically to adapt to changing patterns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf80d571-6dea-4425-a76d-09776943b9cd",
   "metadata": {},
   "source": [
    "## Question No. 8:\n",
    "## List down some commonly used supervised learning algorithms and unsupervised learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08df74d5-0c5b-46fe-830d-cbd5e096905b",
   "metadata": {},
   "source": [
    "## Ans\n",
    "--------\n",
    "list of commonly used supervised learning algorithms and unsupervised learning algorithms:\n",
    "\n",
    "**Supervised Learning Algorithms**:\n",
    "\n",
    "1. **Linear Regression**: Used for regression tasks, where the goal is to predict continuous numerical values (e.g., predicting house prices).\n",
    "\n",
    "2. **Logistic Regression**: Used for binary and multiclass classification tasks, such as spam email detection or image classification.\n",
    "\n",
    "3. **Decision Trees**: Versatile for both classification and regression tasks, decision trees create tree-like structures to make decisions based on features.\n",
    "\n",
    "4. **Random Forest**: An ensemble learning method that combines multiple decision trees to improve accuracy and reduce overfitting.\n",
    "\n",
    "5. **Support Vector Machines (SVM)**: Suitable for classification tasks, SVMs aim to find a hyperplane that best separates data points into different classes.\n",
    "\n",
    "6. **K-Nearest Neighbors (KNN)**: A simple and intuitive algorithm for classification and regression tasks based on similarity to neighboring data points.\n",
    "\n",
    "7. **Naive Bayes**: Particularly useful for text classification and sentiment analysis, Naive Bayes is based on probabilistic principles.\n",
    "\n",
    "8. **Gradient Boosting**: Includes algorithms like AdaBoost, Gradient Boosting, and XGBoost, which iteratively improve model performance by combining weak learners.\n",
    "\n",
    "9. **Neural Networks (Deep Learning)**: Multi-layered artificial neural networks, including Convolutional Neural Networks (CNNs) for images and Recurrent Neural Networks (RNNs) for sequences.\n",
    "\n",
    "10. **Linear Discriminant Analysis (LDA)**: A dimensionality reduction and classification algorithm that aims to maximize class separability.\n",
    "\n",
    "**Unsupervised Learning Algorithms**:\n",
    "\n",
    "1. **K-Means Clustering**: Used to partition data into clusters based on similarity, often employed in customer segmentation and image compression.\n",
    "\n",
    "2. **Hierarchical Clustering**: A method that creates a hierarchical representation of data clusters, visualized as a tree-like structure.\n",
    "\n",
    "3. **Principal Component Analysis (PCA)**: A dimensionality reduction technique used to project high-dimensional data onto a lower-dimensional space.\n",
    "\n",
    "4. **t-Distributed Stochastic Neighbor Embedding (t-SNE)**: Another dimensionality reduction technique, primarily used for visualization of high-dimensional data.\n",
    "\n",
    "5. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**: A density-based clustering algorithm that identifies clusters of varying shapes and sizes.\n",
    "\n",
    "6. **Gaussian Mixture Models (GMM)**: A probabilistic model that represents data as a mixture of Gaussian distributions, useful for density estimation and clustering.\n",
    "\n",
    "7. **Autoencoders**: Neural network architectures used for unsupervised feature learning, dimensionality reduction, and data reconstruction.\n",
    "\n",
    "8. **Isolation Forest**: An ensemble method for anomaly detection, suitable for identifying outliers in datasets.\n",
    "\n",
    "9. **Self-Organizing Maps (SOM)**: A neural network technique used for clustering and visualization of high-dimensional data.\n",
    "\n",
    "10. **Latent Dirichlet Allocation (LDA)**: A generative model used for topic modeling in text data, identifying hidden topics within documents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89446555-3ffd-4f65-a5c1-97b9453e9806",
   "metadata": {},
   "source": [
    "## Ans\n",
    "------\n",
    "### List of commonly used supervised and unsupervised learning algorithms in a table format:\n",
    "\n",
    "**Supervised Learning Algorithms**:\n",
    "\n",
    "| Algorithm                 | Use Cases                              |\n",
    "|---------------------------|----------------------------------------|\n",
    "| Linear Regression         | Regression (predicting continuous values) |\n",
    "| Logistic Regression       | Binary and Multiclass Classification     |\n",
    "| Decision Trees            | Classification, Regression              |\n",
    "| Random Forest             | Classification, Regression              |\n",
    "| Support Vector Machines   | Classification                           |\n",
    "| K-Nearest Neighbors (KNN) | Classification, Regression              |\n",
    "| Naive Bayes               | Classification                           |\n",
    "| Gradient Boosting         | Classification, Regression              |\n",
    "| Neural Networks           | Classification, Regression              |\n",
    "| Linear Discriminant Analysis (LDA) | Classification               |\n",
    "\n",
    "**Unsupervised Learning Algorithms**:\n",
    "\n",
    "| Algorithm                   | Use Cases                                       |\n",
    "|-----------------------------|-------------------------------------------------|\n",
    "| K-Means Clustering          | Clustering, Image Compression                   |\n",
    "| Hierarchical Clustering     | Clustering, Taxonomy Building                   |\n",
    "| Principal Component Analysis (PCA) | Dimensionality Reduction                 |\n",
    "| t-Distributed Stochastic Neighbor Embedding (t-SNE) | Dimensionality Reduction, Visualization |\n",
    "| DBSCAN (Density-Based Spatial Clustering) | Clustering                                |\n",
    "| Gaussian Mixture Models (GMM) | Clustering, Density Estimation             |\n",
    "| Autoencoders                | Feature Learning, Dimensionality Reduction     |\n",
    "| Isolation Forest            | Anomaly Detection                               |\n",
    "| Self-Organizing Maps (SOM)  | Clustering, Visualization                       |\n",
    "| Latent Dirichlet Allocation (LDA) | Topic Modeling in Text Data             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321baf7d-02ec-4ad1-b673-c294421b0003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
